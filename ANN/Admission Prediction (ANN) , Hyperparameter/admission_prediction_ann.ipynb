{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79a41458",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serial No.</th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>396</td>\n",
       "      <td>324</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>9.04</td>\n",
       "      <td>1</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>397</td>\n",
       "      <td>325</td>\n",
       "      <td>107</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>9.11</td>\n",
       "      <td>1</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>398</td>\n",
       "      <td>330</td>\n",
       "      <td>116</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.45</td>\n",
       "      <td>1</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>399</td>\n",
       "      <td>312</td>\n",
       "      <td>103</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.78</td>\n",
       "      <td>0</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>400</td>\n",
       "      <td>333</td>\n",
       "      <td>117</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.66</td>\n",
       "      <td>1</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Serial No.  GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  \\\n",
       "0             1        337          118                  4  4.5   4.5  9.65   \n",
       "1             2        324          107                  4  4.0   4.5  8.87   \n",
       "2             3        316          104                  3  3.0   3.5  8.00   \n",
       "3             4        322          110                  3  3.5   2.5  8.67   \n",
       "4             5        314          103                  2  2.0   3.0  8.21   \n",
       "..          ...        ...          ...                ...  ...   ...   ...   \n",
       "395         396        324          110                  3  3.5   3.5  9.04   \n",
       "396         397        325          107                  3  3.0   3.5  9.11   \n",
       "397         398        330          116                  4  5.0   4.5  9.45   \n",
       "398         399        312          103                  3  3.5   4.0  8.78   \n",
       "399         400        333          117                  4  5.0   4.0  9.66   \n",
       "\n",
       "     Research  Chance of Admit   \n",
       "0           1              0.92  \n",
       "1           1              0.76  \n",
       "2           1              0.72  \n",
       "3           1              0.80  \n",
       "4           0              0.65  \n",
       "..        ...               ...  \n",
       "395         1              0.82  \n",
       "396         1              0.84  \n",
       "397         1              0.91  \n",
       "398         0              0.67  \n",
       "399         1              0.95  \n",
       "\n",
       "[400 rows x 9 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing dataset\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "data = pd.read_csv(\"admission_prediction.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "19f15c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convrting output to binary\n",
    "data[\"Chance of Admit \"] = (data[\"Chance of Admit \"] > 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9cdacfbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>324</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>9.04</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>325</td>\n",
       "      <td>107</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>9.11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>330</td>\n",
       "      <td>116</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.45</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>312</td>\n",
       "      <td>103</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>333</td>\n",
       "      <td>117</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.66</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  Research\n",
       "0          337          118                  4  4.5   4.5  9.65         1\n",
       "1          324          107                  4  4.0   4.5  8.87         1\n",
       "2          316          104                  3  3.0   3.5  8.00         1\n",
       "3          322          110                  3  3.5   2.5  8.67         1\n",
       "4          314          103                  2  2.0   3.0  8.21         0\n",
       "..         ...          ...                ...  ...   ...   ...       ...\n",
       "395        324          110                  3  3.5   3.5  9.04         1\n",
       "396        325          107                  3  3.0   3.5  9.11         1\n",
       "397        330          116                  4  5.0   4.5  9.45         1\n",
       "398        312          103                  3  3.5   4.0  8.78         0\n",
       "399        333          117                  4  5.0   4.0  9.66         1\n",
       "\n",
       "[400 rows x 7 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input dataset\n",
    "data_x = data.drop([\"Chance of Admit \",\"Serial No.\"], axis = 1)\n",
    "data_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "914e92e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       True\n",
       "1       True\n",
       "2       True\n",
       "3       True\n",
       "4      False\n",
       "       ...  \n",
       "395     True\n",
       "396     True\n",
       "397     True\n",
       "398    False\n",
       "399     True\n",
       "Name: Chance of Admit , Length: 400, dtype: bool"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Output dataset\n",
    "data_y = data[\"Chance of Admit \"]\n",
    "data_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "feb26262",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(data_x, data_y, test_size = 0.2, random_state= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b036c933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/360\n",
      "22/22 [==============================] - 1s 19ms/step - loss: 128.2015 - accuracy: 0.5654 - val_loss: 94.9011 - val_accuracy: 0.6321\n",
      "Epoch 2/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 100.3261 - accuracy: 0.5654 - val_loss: 71.6039 - val_accuracy: 0.6321\n",
      "Epoch 3/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 73.6040 - accuracy: 0.5654 - val_loss: 50.8837 - val_accuracy: 0.6321\n",
      "Epoch 4/360\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 48.9256 - accuracy: 0.5654 - val_loss: 30.7635 - val_accuracy: 0.6321\n",
      "Epoch 5/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 25.7655 - accuracy: 0.5654 - val_loss: 10.8746 - val_accuracy: 0.6321\n",
      "Epoch 6/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 5.6103 - accuracy: 0.5000 - val_loss: 2.3712 - val_accuracy: 0.3679\n",
      "Epoch 7/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1.3342 - accuracy: 0.4813 - val_loss: 1.2247 - val_accuracy: 0.3585\n",
      "Epoch 8/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.9454 - accuracy: 0.3832 - val_loss: 0.7673 - val_accuracy: 0.5377\n",
      "Epoch 9/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.8691 - accuracy: 0.4860 - val_loss: 0.9210 - val_accuracy: 0.3679\n",
      "Epoch 10/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.9054 - accuracy: 0.4206 - val_loss: 0.9478 - val_accuracy: 0.3868\n",
      "Epoch 11/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.8564 - accuracy: 0.4112 - val_loss: 0.7921 - val_accuracy: 0.6226\n",
      "Epoch 12/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.8748 - accuracy: 0.4626 - val_loss: 0.7524 - val_accuracy: 0.6038\n",
      "Epoch 13/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.8650 - accuracy: 0.3738 - val_loss: 0.7460 - val_accuracy: 0.6038\n",
      "Epoch 14/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.8444 - accuracy: 0.4626 - val_loss: 0.7519 - val_accuracy: 0.3962\n",
      "Epoch 15/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.8256 - accuracy: 0.4439 - val_loss: 0.7778 - val_accuracy: 0.3491\n",
      "Epoch 16/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.8336 - accuracy: 0.4252 - val_loss: 0.7462 - val_accuracy: 0.4057\n",
      "Epoch 17/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.8332 - accuracy: 0.4159 - val_loss: 0.7898 - val_accuracy: 0.3491\n",
      "Epoch 18/360\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.8466 - accuracy: 0.4579 - val_loss: 0.7212 - val_accuracy: 0.5377\n",
      "Epoch 19/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.8171 - accuracy: 0.4860 - val_loss: 0.7099 - val_accuracy: 0.6226\n",
      "Epoch 20/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.8391 - accuracy: 0.4533 - val_loss: 1.0773 - val_accuracy: 0.3774\n",
      "Epoch 21/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.8776 - accuracy: 0.4533 - val_loss: 0.7148 - val_accuracy: 0.6132\n",
      "Epoch 22/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.7966 - accuracy: 0.4673 - val_loss: 0.7481 - val_accuracy: 0.4057\n",
      "Epoch 23/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.7725 - accuracy: 0.4766 - val_loss: 0.8118 - val_accuracy: 0.4151\n",
      "Epoch 24/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.7755 - accuracy: 0.5093 - val_loss: 0.9556 - val_accuracy: 0.3868\n",
      "Epoch 25/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.7522 - accuracy: 0.5234 - val_loss: 0.6828 - val_accuracy: 0.6132\n",
      "Epoch 26/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.7489 - accuracy: 0.4720 - val_loss: 0.6778 - val_accuracy: 0.6226\n",
      "Epoch 27/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.7403 - accuracy: 0.4953 - val_loss: 0.6764 - val_accuracy: 0.5849\n",
      "Epoch 28/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.8128 - accuracy: 0.5187 - val_loss: 0.6660 - val_accuracy: 0.6321\n",
      "Epoch 29/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.7766 - accuracy: 0.4533 - val_loss: 0.6623 - val_accuracy: 0.6415\n",
      "Epoch 30/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.7526 - accuracy: 0.5047 - val_loss: 0.8023 - val_accuracy: 0.4434\n",
      "Epoch 31/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.7547 - accuracy: 0.5280 - val_loss: 0.7657 - val_accuracy: 0.4906\n",
      "Epoch 32/360\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.7104 - accuracy: 0.5187 - val_loss: 0.7340 - val_accuracy: 0.5000\n",
      "Epoch 33/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.7288 - accuracy: 0.5047 - val_loss: 0.6469 - val_accuracy: 0.6509\n",
      "Epoch 34/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.7965 - accuracy: 0.4813 - val_loss: 0.6419 - val_accuracy: 0.6132\n",
      "Epoch 35/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.6984 - accuracy: 0.5794 - val_loss: 0.6398 - val_accuracy: 0.6415\n",
      "Epoch 36/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.7411 - accuracy: 0.5187 - val_loss: 0.6336 - val_accuracy: 0.6415\n",
      "Epoch 37/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.7255 - accuracy: 0.5888 - val_loss: 0.6299 - val_accuracy: 0.6604\n",
      "Epoch 38/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.7414 - accuracy: 0.5047 - val_loss: 0.6542 - val_accuracy: 0.6226\n",
      "Epoch 39/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.7685 - accuracy: 0.5561 - val_loss: 0.6285 - val_accuracy: 0.6038\n",
      "Epoch 40/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.6646 - accuracy: 0.6121 - val_loss: 0.7191 - val_accuracy: 0.5660\n",
      "Epoch 41/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.6909 - accuracy: 0.6075 - val_loss: 0.6189 - val_accuracy: 0.6604\n",
      "Epoch 42/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.7043 - accuracy: 0.5607 - val_loss: 0.6498 - val_accuracy: 0.5849\n",
      "Epoch 43/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.7119 - accuracy: 0.6028 - val_loss: 0.6121 - val_accuracy: 0.6321\n",
      "Epoch 44/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.7320 - accuracy: 0.5467 - val_loss: 0.6067 - val_accuracy: 0.6604\n",
      "Epoch 45/360\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.6459 - accuracy: 0.5888 - val_loss: 0.6082 - val_accuracy: 0.6604\n",
      "Epoch 46/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.6368 - accuracy: 0.6121 - val_loss: 0.6308 - val_accuracy: 0.6226\n",
      "Epoch 47/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.6373 - accuracy: 0.6262 - val_loss: 0.6004 - val_accuracy: 0.6226\n",
      "Epoch 48/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.7017 - accuracy: 0.5888 - val_loss: 0.5955 - val_accuracy: 0.6698\n",
      "Epoch 49/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.6536 - accuracy: 0.6168 - val_loss: 0.5926 - val_accuracy: 0.6509\n",
      "Epoch 50/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.6329 - accuracy: 0.6308 - val_loss: 0.6089 - val_accuracy: 0.6226\n",
      "Epoch 51/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.6108 - accuracy: 0.6636 - val_loss: 0.5887 - val_accuracy: 0.6604\n",
      "Epoch 52/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.6878 - accuracy: 0.5467 - val_loss: 0.6133 - val_accuracy: 0.6415\n",
      "Epoch 53/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.6440 - accuracy: 0.6028 - val_loss: 0.5822 - val_accuracy: 0.6604\n",
      "Epoch 54/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.6363 - accuracy: 0.6075 - val_loss: 0.6215 - val_accuracy: 0.6415\n",
      "Epoch 55/360\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.6396 - accuracy: 0.6402 - val_loss: 0.5819 - val_accuracy: 0.6604\n",
      "Epoch 56/360\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.5933 - accuracy: 0.6636 - val_loss: 0.5862 - val_accuracy: 0.6698\n",
      "Epoch 57/360\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.6309 - accuracy: 0.6449 - val_loss: 0.6010 - val_accuracy: 0.6509\n",
      "Epoch 58/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.6044 - accuracy: 0.6776 - val_loss: 0.6188 - val_accuracy: 0.6792\n",
      "Epoch 59/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.6039 - accuracy: 0.6589 - val_loss: 0.6490 - val_accuracy: 0.6321\n",
      "Epoch 60/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.6808 - accuracy: 0.6355 - val_loss: 0.7249 - val_accuracy: 0.5943\n",
      "Epoch 61/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.6213 - accuracy: 0.6355 - val_loss: 0.6988 - val_accuracy: 0.6321\n",
      "Epoch 62/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.6605 - accuracy: 0.6308 - val_loss: 0.5620 - val_accuracy: 0.6887\n",
      "Epoch 63/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.6495 - accuracy: 0.6215 - val_loss: 0.5614 - val_accuracy: 0.6792\n",
      "Epoch 64/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.5674 - accuracy: 0.7150 - val_loss: 0.5613 - val_accuracy: 0.7170\n",
      "Epoch 65/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.5764 - accuracy: 0.7009 - val_loss: 0.5649 - val_accuracy: 0.6981\n",
      "Epoch 66/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.5560 - accuracy: 0.7477 - val_loss: 0.5697 - val_accuracy: 0.6604\n",
      "Epoch 67/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.5610 - accuracy: 0.6963 - val_loss: 0.5536 - val_accuracy: 0.6887\n",
      "Epoch 68/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.5610 - accuracy: 0.6963 - val_loss: 0.5870 - val_accuracy: 0.6698\n",
      "Epoch 69/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.6386 - accuracy: 0.6495 - val_loss: 0.6191 - val_accuracy: 0.6415\n",
      "Epoch 70/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.6004 - accuracy: 0.6916 - val_loss: 0.6149 - val_accuracy: 0.6415\n",
      "Epoch 71/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.5747 - accuracy: 0.6542 - val_loss: 0.6201 - val_accuracy: 0.6509\n",
      "Epoch 72/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.5382 - accuracy: 0.7103 - val_loss: 0.5602 - val_accuracy: 0.7075\n",
      "Epoch 73/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.5514 - accuracy: 0.7243 - val_loss: 0.5541 - val_accuracy: 0.6792\n",
      "Epoch 74/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.5397 - accuracy: 0.7383 - val_loss: 0.5677 - val_accuracy: 0.6981\n",
      "Epoch 75/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.5573 - accuracy: 0.7103 - val_loss: 0.6393 - val_accuracy: 0.6415\n",
      "Epoch 76/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.5848 - accuracy: 0.6682 - val_loss: 0.5460 - val_accuracy: 0.7170\n",
      "Epoch 77/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.5181 - accuracy: 0.7430 - val_loss: 0.5555 - val_accuracy: 0.6698\n",
      "Epoch 78/360\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.5529 - accuracy: 0.6963 - val_loss: 0.5635 - val_accuracy: 0.7075\n",
      "Epoch 79/360\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.5265 - accuracy: 0.7430 - val_loss: 0.5351 - val_accuracy: 0.7358\n",
      "Epoch 80/360\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.5176 - accuracy: 0.7243 - val_loss: 0.6148 - val_accuracy: 0.6792\n",
      "Epoch 81/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.5631 - accuracy: 0.6963 - val_loss: 0.5406 - val_accuracy: 0.7264\n",
      "Epoch 82/360\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.5157 - accuracy: 0.7430 - val_loss: 0.5325 - val_accuracy: 0.7170\n",
      "Epoch 83/360\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.5444 - accuracy: 0.7103 - val_loss: 0.5298 - val_accuracy: 0.7170\n",
      "Epoch 84/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.5703 - accuracy: 0.6869 - val_loss: 0.5582 - val_accuracy: 0.7075\n",
      "Epoch 85/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.5215 - accuracy: 0.7477 - val_loss: 0.5298 - val_accuracy: 0.7264\n",
      "Epoch 86/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.5308 - accuracy: 0.7103 - val_loss: 0.5339 - val_accuracy: 0.7358\n",
      "Epoch 87/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.5243 - accuracy: 0.7570 - val_loss: 0.5257 - val_accuracy: 0.7075\n",
      "Epoch 88/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4929 - accuracy: 0.7710 - val_loss: 0.5744 - val_accuracy: 0.6604\n",
      "Epoch 89/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.5295 - accuracy: 0.6822 - val_loss: 0.8683 - val_accuracy: 0.5094\n",
      "Epoch 90/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.5293 - accuracy: 0.7477 - val_loss: 0.5449 - val_accuracy: 0.7358\n",
      "Epoch 91/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.5264 - accuracy: 0.7430 - val_loss: 0.5262 - val_accuracy: 0.7358\n",
      "Epoch 92/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4882 - accuracy: 0.7710 - val_loss: 0.5283 - val_accuracy: 0.7453\n",
      "Epoch 93/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4985 - accuracy: 0.7757 - val_loss: 0.7268 - val_accuracy: 0.5943\n",
      "Epoch 94/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.5997 - accuracy: 0.6729 - val_loss: 0.6991 - val_accuracy: 0.5849\n",
      "Epoch 95/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.5193 - accuracy: 0.7570 - val_loss: 0.5614 - val_accuracy: 0.6887\n",
      "Epoch 96/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4828 - accuracy: 0.7804 - val_loss: 0.5523 - val_accuracy: 0.7170\n",
      "Epoch 97/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.5004 - accuracy: 0.7850 - val_loss: 0.5500 - val_accuracy: 0.6981\n",
      "Epoch 98/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4989 - accuracy: 0.7570 - val_loss: 0.7327 - val_accuracy: 0.5943\n",
      "Epoch 99/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.5817 - accuracy: 0.6729 - val_loss: 0.5780 - val_accuracy: 0.6981\n",
      "Epoch 100/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.5036 - accuracy: 0.7290 - val_loss: 0.6044 - val_accuracy: 0.6792\n",
      "Epoch 101/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4929 - accuracy: 0.7477 - val_loss: 0.5359 - val_accuracy: 0.7264\n",
      "Epoch 102/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4839 - accuracy: 0.7383 - val_loss: 0.5264 - val_accuracy: 0.7547\n",
      "Epoch 103/360\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.4838 - accuracy: 0.7710 - val_loss: 0.5120 - val_accuracy: 0.7264\n",
      "Epoch 104/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4887 - accuracy: 0.7430 - val_loss: 0.5273 - val_accuracy: 0.7358\n",
      "Epoch 105/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4949 - accuracy: 0.7430 - val_loss: 0.6346 - val_accuracy: 0.6321\n",
      "Epoch 106/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4664 - accuracy: 0.7383 - val_loss: 0.5447 - val_accuracy: 0.7264\n",
      "Epoch 107/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4754 - accuracy: 0.7757 - val_loss: 0.5793 - val_accuracy: 0.6981\n",
      "Epoch 108/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.5215 - accuracy: 0.7243 - val_loss: 0.5745 - val_accuracy: 0.6981\n",
      "Epoch 109/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.5057 - accuracy: 0.7243 - val_loss: 0.5177 - val_accuracy: 0.7547\n",
      "Epoch 110/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4700 - accuracy: 0.7710 - val_loss: 0.5103 - val_accuracy: 0.7642\n",
      "Epoch 111/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.5200 - accuracy: 0.6916 - val_loss: 0.5219 - val_accuracy: 0.7453\n",
      "Epoch 112/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4678 - accuracy: 0.7757 - val_loss: 0.5138 - val_accuracy: 0.7642\n",
      "Epoch 113/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4657 - accuracy: 0.7757 - val_loss: 0.5529 - val_accuracy: 0.6981\n",
      "Epoch 114/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4705 - accuracy: 0.7570 - val_loss: 0.6659 - val_accuracy: 0.6604\n",
      "Epoch 115/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.5415 - accuracy: 0.7336 - val_loss: 0.7324 - val_accuracy: 0.5849\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 116/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4937 - accuracy: 0.7383 - val_loss: 0.5683 - val_accuracy: 0.6981\n",
      "Epoch 117/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4716 - accuracy: 0.7523 - val_loss: 0.5078 - val_accuracy: 0.7830\n",
      "Epoch 118/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4499 - accuracy: 0.7804 - val_loss: 0.5625 - val_accuracy: 0.6981\n",
      "Epoch 119/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.5013 - accuracy: 0.7336 - val_loss: 0.5053 - val_accuracy: 0.7358\n",
      "Epoch 120/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4593 - accuracy: 0.7710 - val_loss: 0.5203 - val_accuracy: 0.7453\n",
      "Epoch 121/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4596 - accuracy: 0.7710 - val_loss: 0.5036 - val_accuracy: 0.7642\n",
      "Epoch 122/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.5144 - accuracy: 0.7570 - val_loss: 0.6992 - val_accuracy: 0.6509\n",
      "Epoch 123/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.5559 - accuracy: 0.6916 - val_loss: 0.6193 - val_accuracy: 0.6698\n",
      "Epoch 124/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4664 - accuracy: 0.7617 - val_loss: 0.5547 - val_accuracy: 0.7170\n",
      "Epoch 125/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4802 - accuracy: 0.7523 - val_loss: 0.5095 - val_accuracy: 0.7358\n",
      "Epoch 126/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4499 - accuracy: 0.7617 - val_loss: 0.5073 - val_accuracy: 0.7642\n",
      "Epoch 127/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4721 - accuracy: 0.7570 - val_loss: 0.5053 - val_accuracy: 0.7642\n",
      "Epoch 128/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4779 - accuracy: 0.7617 - val_loss: 0.6462 - val_accuracy: 0.6226\n",
      "Epoch 129/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.5148 - accuracy: 0.7290 - val_loss: 0.5009 - val_accuracy: 0.7642\n",
      "Epoch 130/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4467 - accuracy: 0.7664 - val_loss: 0.5982 - val_accuracy: 0.6887\n",
      "Epoch 131/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4742 - accuracy: 0.7430 - val_loss: 0.5132 - val_accuracy: 0.7642\n",
      "Epoch 132/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4619 - accuracy: 0.7897 - val_loss: 0.5247 - val_accuracy: 0.7358\n",
      "Epoch 133/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4485 - accuracy: 0.7664 - val_loss: 0.5317 - val_accuracy: 0.7453\n",
      "Epoch 134/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4356 - accuracy: 0.7757 - val_loss: 0.5935 - val_accuracy: 0.7170\n",
      "Epoch 135/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4903 - accuracy: 0.7710 - val_loss: 0.5491 - val_accuracy: 0.7453\n",
      "Epoch 136/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4577 - accuracy: 0.7617 - val_loss: 0.5505 - val_accuracy: 0.7358\n",
      "Epoch 137/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4610 - accuracy: 0.7804 - val_loss: 0.5138 - val_accuracy: 0.7547\n",
      "Epoch 138/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4196 - accuracy: 0.7804 - val_loss: 0.5137 - val_accuracy: 0.7547\n",
      "Epoch 139/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4264 - accuracy: 0.7897 - val_loss: 0.7119 - val_accuracy: 0.6321\n",
      "Epoch 140/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.5196 - accuracy: 0.7477 - val_loss: 0.5217 - val_accuracy: 0.7547\n",
      "Epoch 141/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4877 - accuracy: 0.7850 - val_loss: 0.5884 - val_accuracy: 0.7358\n",
      "Epoch 142/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4274 - accuracy: 0.8131 - val_loss: 0.6000 - val_accuracy: 0.6887\n",
      "Epoch 143/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4472 - accuracy: 0.7804 - val_loss: 0.5127 - val_accuracy: 0.7736\n",
      "Epoch 144/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4159 - accuracy: 0.7944 - val_loss: 0.5137 - val_accuracy: 0.7642\n",
      "Epoch 145/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4426 - accuracy: 0.7804 - val_loss: 0.5147 - val_accuracy: 0.7642\n",
      "Epoch 146/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4206 - accuracy: 0.8131 - val_loss: 0.5202 - val_accuracy: 0.7642\n",
      "Epoch 147/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4398 - accuracy: 0.7477 - val_loss: 0.5812 - val_accuracy: 0.6981\n",
      "Epoch 148/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.5099 - accuracy: 0.7617 - val_loss: 0.6714 - val_accuracy: 0.7170\n",
      "Epoch 149/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4619 - accuracy: 0.7850 - val_loss: 0.5710 - val_accuracy: 0.7358\n",
      "Epoch 150/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4251 - accuracy: 0.7850 - val_loss: 0.5397 - val_accuracy: 0.7453\n",
      "Epoch 151/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4504 - accuracy: 0.7850 - val_loss: 0.5927 - val_accuracy: 0.7264\n",
      "Epoch 152/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4995 - accuracy: 0.7383 - val_loss: 0.5555 - val_accuracy: 0.7453\n",
      "Epoch 153/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.5140 - accuracy: 0.7757 - val_loss: 0.5133 - val_accuracy: 0.7642\n",
      "Epoch 154/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.5593 - accuracy: 0.7196 - val_loss: 0.7098 - val_accuracy: 0.6321\n",
      "Epoch 155/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4655 - accuracy: 0.7617 - val_loss: 0.5871 - val_accuracy: 0.7453\n",
      "Epoch 156/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4244 - accuracy: 0.7944 - val_loss: 0.5892 - val_accuracy: 0.6887\n",
      "Epoch 157/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4638 - accuracy: 0.7991 - val_loss: 0.5702 - val_accuracy: 0.7358\n",
      "Epoch 158/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4600 - accuracy: 0.7710 - val_loss: 0.6839 - val_accuracy: 0.6698\n",
      "Epoch 159/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.5316 - accuracy: 0.7430 - val_loss: 0.6268 - val_accuracy: 0.7170\n",
      "Epoch 160/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4461 - accuracy: 0.7897 - val_loss: 0.5464 - val_accuracy: 0.7453\n",
      "Epoch 161/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4248 - accuracy: 0.7664 - val_loss: 0.5214 - val_accuracy: 0.7736\n",
      "Epoch 162/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4239 - accuracy: 0.7804 - val_loss: 0.5291 - val_accuracy: 0.7642\n",
      "Epoch 163/360\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.4179 - accuracy: 0.7757 - val_loss: 0.5213 - val_accuracy: 0.7830\n",
      "Epoch 164/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4195 - accuracy: 0.7804 - val_loss: 0.5249 - val_accuracy: 0.7642\n",
      "Epoch 165/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.5913 - accuracy: 0.7150 - val_loss: 0.9308 - val_accuracy: 0.5943\n",
      "Epoch 166/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4953 - accuracy: 0.7570 - val_loss: 0.5176 - val_accuracy: 0.7736\n",
      "Epoch 167/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4137 - accuracy: 0.7850 - val_loss: 0.5915 - val_accuracy: 0.6981\n",
      "Epoch 168/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4447 - accuracy: 0.7804 - val_loss: 0.5803 - val_accuracy: 0.7358\n",
      "Epoch 169/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4817 - accuracy: 0.7664 - val_loss: 0.6058 - val_accuracy: 0.6887\n",
      "Epoch 170/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.5105 - accuracy: 0.7570 - val_loss: 0.5137 - val_accuracy: 0.7642\n",
      "Epoch 171/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4281 - accuracy: 0.7804 - val_loss: 0.7706 - val_accuracy: 0.6038\n",
      "Epoch 172/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.6706 - accuracy: 0.7009 - val_loss: 0.8475 - val_accuracy: 0.6698\n",
      "Epoch 173/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4388 - accuracy: 0.7804 - val_loss: 0.5777 - val_accuracy: 0.7264\n",
      "Epoch 174/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4149 - accuracy: 0.7897 - val_loss: 0.5140 - val_accuracy: 0.7736\n",
      "Epoch 175/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4190 - accuracy: 0.7944 - val_loss: 0.5425 - val_accuracy: 0.7453\n",
      "Epoch 176/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.3965 - accuracy: 0.8271 - val_loss: 0.5217 - val_accuracy: 0.7736\n",
      "Epoch 177/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4508 - accuracy: 0.7897 - val_loss: 0.5441 - val_accuracy: 0.7453\n",
      "Epoch 178/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4240 - accuracy: 0.7944 - val_loss: 0.5447 - val_accuracy: 0.7453\n",
      "Epoch 179/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4179 - accuracy: 0.7804 - val_loss: 0.5608 - val_accuracy: 0.7453\n",
      "Epoch 180/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4776 - accuracy: 0.7243 - val_loss: 0.7259 - val_accuracy: 0.6415\n",
      "Epoch 181/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4504 - accuracy: 0.7617 - val_loss: 0.5686 - val_accuracy: 0.7264\n",
      "Epoch 182/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4191 - accuracy: 0.7897 - val_loss: 0.5454 - val_accuracy: 0.7453\n",
      "Epoch 183/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4258 - accuracy: 0.7897 - val_loss: 0.6209 - val_accuracy: 0.7170\n",
      "Epoch 184/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4215 - accuracy: 0.7804 - val_loss: 0.5280 - val_accuracy: 0.7642\n",
      "Epoch 185/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4143 - accuracy: 0.7944 - val_loss: 0.5140 - val_accuracy: 0.7736\n",
      "Epoch 186/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4247 - accuracy: 0.7850 - val_loss: 0.6286 - val_accuracy: 0.6792\n",
      "Epoch 187/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4734 - accuracy: 0.7570 - val_loss: 0.5141 - val_accuracy: 0.7830\n",
      "Epoch 188/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4448 - accuracy: 0.7944 - val_loss: 0.5147 - val_accuracy: 0.7830\n",
      "Epoch 189/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4236 - accuracy: 0.7944 - val_loss: 0.5180 - val_accuracy: 0.7736\n",
      "Epoch 190/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.3962 - accuracy: 0.8271 - val_loss: 0.5281 - val_accuracy: 0.7642\n",
      "Epoch 191/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4142 - accuracy: 0.7991 - val_loss: 0.5563 - val_accuracy: 0.7453\n",
      "Epoch 192/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4143 - accuracy: 0.8131 - val_loss: 0.5220 - val_accuracy: 0.7736\n",
      "Epoch 193/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4416 - accuracy: 0.7897 - val_loss: 0.5143 - val_accuracy: 0.7925\n",
      "Epoch 194/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4060 - accuracy: 0.7991 - val_loss: 0.5142 - val_accuracy: 0.7830\n",
      "Epoch 195/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4188 - accuracy: 0.7804 - val_loss: 0.5607 - val_accuracy: 0.7358\n",
      "Epoch 196/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4560 - accuracy: 0.7897 - val_loss: 0.5781 - val_accuracy: 0.7264\n",
      "Epoch 197/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4175 - accuracy: 0.8178 - val_loss: 0.5141 - val_accuracy: 0.7830\n",
      "Epoch 198/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4913 - accuracy: 0.7617 - val_loss: 0.5475 - val_accuracy: 0.7453\n",
      "Epoch 199/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.5361 - accuracy: 0.7336 - val_loss: 1.0909 - val_accuracy: 0.5660\n",
      "Epoch 200/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4765 - accuracy: 0.7617 - val_loss: 0.5143 - val_accuracy: 0.7736\n",
      "Epoch 201/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4446 - accuracy: 0.7897 - val_loss: 0.6039 - val_accuracy: 0.7358\n",
      "Epoch 202/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4448 - accuracy: 0.7804 - val_loss: 0.5314 - val_accuracy: 0.7642\n",
      "Epoch 203/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4058 - accuracy: 0.7991 - val_loss: 0.6402 - val_accuracy: 0.7170\n",
      "Epoch 204/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.5175 - accuracy: 0.7336 - val_loss: 0.6063 - val_accuracy: 0.6887\n",
      "Epoch 205/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.5035 - accuracy: 0.7336 - val_loss: 0.6803 - val_accuracy: 0.7170\n",
      "Epoch 206/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.5098 - accuracy: 0.7523 - val_loss: 0.5319 - val_accuracy: 0.7642\n",
      "Epoch 207/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4599 - accuracy: 0.7897 - val_loss: 0.5308 - val_accuracy: 0.7736\n",
      "Epoch 208/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4789 - accuracy: 0.7617 - val_loss: 0.6491 - val_accuracy: 0.6792\n",
      "Epoch 209/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4241 - accuracy: 0.7804 - val_loss: 0.5149 - val_accuracy: 0.7736\n",
      "Epoch 210/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4274 - accuracy: 0.7944 - val_loss: 0.5247 - val_accuracy: 0.7547\n",
      "Epoch 211/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4453 - accuracy: 0.7897 - val_loss: 0.5151 - val_accuracy: 0.7830\n",
      "Epoch 212/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4317 - accuracy: 0.7804 - val_loss: 0.5340 - val_accuracy: 0.7642\n",
      "Epoch 213/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.5202 - accuracy: 0.7196 - val_loss: 0.6248 - val_accuracy: 0.6792\n",
      "Epoch 214/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4112 - accuracy: 0.7804 - val_loss: 0.6305 - val_accuracy: 0.7170\n",
      "Epoch 215/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4339 - accuracy: 0.7991 - val_loss: 0.6244 - val_accuracy: 0.6792\n",
      "Epoch 216/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.5558 - accuracy: 0.7290 - val_loss: 0.5562 - val_accuracy: 0.7358\n",
      "Epoch 217/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4228 - accuracy: 0.7897 - val_loss: 0.5211 - val_accuracy: 0.7736\n",
      "Epoch 218/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4513 - accuracy: 0.7897 - val_loss: 0.5206 - val_accuracy: 0.7736\n",
      "Epoch 219/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4305 - accuracy: 0.7804 - val_loss: 0.5372 - val_accuracy: 0.7547\n",
      "Epoch 220/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4289 - accuracy: 0.7757 - val_loss: 0.5988 - val_accuracy: 0.7075\n",
      "Epoch 221/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4644 - accuracy: 0.7664 - val_loss: 0.5144 - val_accuracy: 0.8019\n",
      "Epoch 222/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4262 - accuracy: 0.7804 - val_loss: 0.5928 - val_accuracy: 0.7075\n",
      "Epoch 223/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4324 - accuracy: 0.7991 - val_loss: 0.5143 - val_accuracy: 0.8019\n",
      "Epoch 224/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4145 - accuracy: 0.7897 - val_loss: 0.5372 - val_accuracy: 0.7642\n",
      "Epoch 225/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.3965 - accuracy: 0.7897 - val_loss: 0.5153 - val_accuracy: 0.7736\n",
      "Epoch 226/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4153 - accuracy: 0.7944 - val_loss: 0.5306 - val_accuracy: 0.7642\n",
      "Epoch 227/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4115 - accuracy: 0.7897 - val_loss: 0.5401 - val_accuracy: 0.7453\n",
      "Epoch 228/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4156 - accuracy: 0.8037 - val_loss: 0.5143 - val_accuracy: 0.7925\n",
      "Epoch 229/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.3918 - accuracy: 0.8364 - val_loss: 0.5203 - val_accuracy: 0.7830\n",
      "Epoch 230/360\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4834 - accuracy: 0.7617 - val_loss: 0.8894 - val_accuracy: 0.6038\n",
      "Epoch 231/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4741 - accuracy: 0.7570 - val_loss: 0.5602 - val_accuracy: 0.7453\n",
      "Epoch 232/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4023 - accuracy: 0.7944 - val_loss: 0.5222 - val_accuracy: 0.7736\n",
      "Epoch 233/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4071 - accuracy: 0.8037 - val_loss: 0.5209 - val_accuracy: 0.7830\n",
      "Epoch 234/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4076 - accuracy: 0.7710 - val_loss: 0.5970 - val_accuracy: 0.7075\n",
      "Epoch 235/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4727 - accuracy: 0.7664 - val_loss: 0.5448 - val_accuracy: 0.7736\n",
      "Epoch 236/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4661 - accuracy: 0.7757 - val_loss: 0.5515 - val_accuracy: 0.7264\n",
      "Epoch 237/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4350 - accuracy: 0.7944 - val_loss: 0.5212 - val_accuracy: 0.7736\n",
      "Epoch 238/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4689 - accuracy: 0.7850 - val_loss: 0.5142 - val_accuracy: 0.7925\n",
      "Epoch 239/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4140 - accuracy: 0.7944 - val_loss: 0.6530 - val_accuracy: 0.7170\n",
      "Epoch 240/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.5335 - accuracy: 0.7383 - val_loss: 0.8716 - val_accuracy: 0.5943\n",
      "Epoch 241/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.5312 - accuracy: 0.7664 - val_loss: 0.5179 - val_accuracy: 0.7736\n",
      "Epoch 242/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4155 - accuracy: 0.8131 - val_loss: 0.6732 - val_accuracy: 0.6698\n",
      "Epoch 243/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.5959 - accuracy: 0.7196 - val_loss: 0.5515 - val_accuracy: 0.7358\n",
      "Epoch 244/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4378 - accuracy: 0.8037 - val_loss: 0.5424 - val_accuracy: 0.7453\n",
      "Epoch 245/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4157 - accuracy: 0.8037 - val_loss: 0.5214 - val_accuracy: 0.7642\n",
      "Epoch 246/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4322 - accuracy: 0.7991 - val_loss: 0.5262 - val_accuracy: 0.7925\n",
      "Epoch 247/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4191 - accuracy: 0.7897 - val_loss: 0.5147 - val_accuracy: 0.7925\n",
      "Epoch 248/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4245 - accuracy: 0.7897 - val_loss: 0.5146 - val_accuracy: 0.7830\n",
      "Epoch 249/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4631 - accuracy: 0.7991 - val_loss: 0.5274 - val_accuracy: 0.7547\n",
      "Epoch 250/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4194 - accuracy: 0.8131 - val_loss: 0.5169 - val_accuracy: 0.7830\n",
      "Epoch 251/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.3944 - accuracy: 0.8037 - val_loss: 0.5259 - val_accuracy: 0.7547\n",
      "Epoch 252/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4664 - accuracy: 0.7944 - val_loss: 0.5729 - val_accuracy: 0.7358\n",
      "Epoch 253/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4207 - accuracy: 0.7897 - val_loss: 0.5577 - val_accuracy: 0.7358\n",
      "Epoch 254/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4315 - accuracy: 0.8131 - val_loss: 0.5365 - val_accuracy: 0.7736\n",
      "Epoch 255/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4402 - accuracy: 0.7804 - val_loss: 0.5191 - val_accuracy: 0.7830\n",
      "Epoch 256/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.3894 - accuracy: 0.8084 - val_loss: 0.6135 - val_accuracy: 0.7264\n",
      "Epoch 257/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4936 - accuracy: 0.7570 - val_loss: 0.5723 - val_accuracy: 0.7453\n",
      "Epoch 258/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4234 - accuracy: 0.7804 - val_loss: 0.5318 - val_accuracy: 0.7830\n",
      "Epoch 259/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4282 - accuracy: 0.8037 - val_loss: 0.5429 - val_accuracy: 0.7453\n",
      "Epoch 260/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4225 - accuracy: 0.8037 - val_loss: 0.6068 - val_accuracy: 0.6981\n",
      "Epoch 261/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4163 - accuracy: 0.8037 - val_loss: 0.5217 - val_accuracy: 0.7830\n",
      "Epoch 262/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4105 - accuracy: 0.8131 - val_loss: 0.5149 - val_accuracy: 0.7830\n",
      "Epoch 263/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4254 - accuracy: 0.7850 - val_loss: 0.5240 - val_accuracy: 0.7736\n",
      "Epoch 264/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4197 - accuracy: 0.8084 - val_loss: 0.5151 - val_accuracy: 0.7830\n",
      "Epoch 265/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4099 - accuracy: 0.8037 - val_loss: 0.5525 - val_accuracy: 0.7358\n",
      "Epoch 266/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4173 - accuracy: 0.7850 - val_loss: 0.5142 - val_accuracy: 0.7925\n",
      "Epoch 267/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4152 - accuracy: 0.7991 - val_loss: 0.6487 - val_accuracy: 0.6792\n",
      "Epoch 268/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4118 - accuracy: 0.7991 - val_loss: 0.5414 - val_accuracy: 0.7453\n",
      "Epoch 269/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4060 - accuracy: 0.7944 - val_loss: 0.5593 - val_accuracy: 0.7453\n",
      "Epoch 270/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.5135 - accuracy: 0.7383 - val_loss: 0.5136 - val_accuracy: 0.7830\n",
      "Epoch 271/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4404 - accuracy: 0.8084 - val_loss: 0.5192 - val_accuracy: 0.7642\n",
      "Epoch 272/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4169 - accuracy: 0.7617 - val_loss: 0.5789 - val_accuracy: 0.7358\n",
      "Epoch 273/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4158 - accuracy: 0.7944 - val_loss: 0.5270 - val_accuracy: 0.7547\n",
      "Epoch 274/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4233 - accuracy: 0.7757 - val_loss: 0.5163 - val_accuracy: 0.8019\n",
      "Epoch 275/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.3958 - accuracy: 0.7944 - val_loss: 0.5493 - val_accuracy: 0.7453\n",
      "Epoch 276/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4044 - accuracy: 0.7991 - val_loss: 0.5155 - val_accuracy: 0.7830\n",
      "Epoch 277/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4422 - accuracy: 0.7757 - val_loss: 0.5204 - val_accuracy: 0.7830\n",
      "Epoch 278/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4225 - accuracy: 0.8084 - val_loss: 0.5141 - val_accuracy: 0.7830\n",
      "Epoch 279/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4252 - accuracy: 0.7944 - val_loss: 0.5392 - val_accuracy: 0.7453\n",
      "Epoch 280/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4092 - accuracy: 0.7897 - val_loss: 0.6055 - val_accuracy: 0.6981\n",
      "Epoch 281/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4345 - accuracy: 0.7897 - val_loss: 0.5399 - val_accuracy: 0.7642\n",
      "Epoch 282/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4288 - accuracy: 0.7897 - val_loss: 0.5297 - val_accuracy: 0.7453\n",
      "Epoch 283/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4081 - accuracy: 0.7897 - val_loss: 0.5387 - val_accuracy: 0.7453\n",
      "Epoch 284/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4024 - accuracy: 0.8037 - val_loss: 0.5739 - val_accuracy: 0.7358\n",
      "Epoch 285/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4335 - accuracy: 0.7850 - val_loss: 0.6627 - val_accuracy: 0.6792\n",
      "Epoch 286/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4471 - accuracy: 0.7850 - val_loss: 0.5164 - val_accuracy: 0.7736\n",
      "Epoch 287/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4315 - accuracy: 0.8131 - val_loss: 0.5782 - val_accuracy: 0.7358\n",
      "Epoch 288/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4138 - accuracy: 0.7710 - val_loss: 0.5165 - val_accuracy: 0.8019\n",
      "Epoch 289/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.3995 - accuracy: 0.8131 - val_loss: 0.6320 - val_accuracy: 0.7264\n",
      "Epoch 290/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4363 - accuracy: 0.7991 - val_loss: 0.6478 - val_accuracy: 0.6792\n",
      "Epoch 291/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4546 - accuracy: 0.7757 - val_loss: 0.5171 - val_accuracy: 0.7642\n",
      "Epoch 292/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4950 - accuracy: 0.7477 - val_loss: 0.9934 - val_accuracy: 0.6132\n",
      "Epoch 293/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.5541 - accuracy: 0.7430 - val_loss: 0.5143 - val_accuracy: 0.7925\n",
      "Epoch 294/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4130 - accuracy: 0.7991 - val_loss: 0.5157 - val_accuracy: 0.8019\n",
      "Epoch 295/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.3990 - accuracy: 0.8178 - val_loss: 0.5122 - val_accuracy: 0.7830\n",
      "Epoch 296/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4044 - accuracy: 0.8178 - val_loss: 0.5197 - val_accuracy: 0.7736\n",
      "Epoch 297/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4111 - accuracy: 0.7944 - val_loss: 0.6060 - val_accuracy: 0.6981\n",
      "Epoch 298/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4452 - accuracy: 0.7757 - val_loss: 0.5290 - val_accuracy: 0.7830\n",
      "Epoch 299/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4033 - accuracy: 0.7991 - val_loss: 0.5155 - val_accuracy: 0.8019\n",
      "Epoch 300/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4466 - accuracy: 0.7710 - val_loss: 0.5155 - val_accuracy: 0.8019\n",
      "Epoch 301/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4076 - accuracy: 0.7804 - val_loss: 0.5124 - val_accuracy: 0.7925\n",
      "Epoch 302/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.3923 - accuracy: 0.8131 - val_loss: 0.5140 - val_accuracy: 0.7925\n",
      "Epoch 303/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4076 - accuracy: 0.8084 - val_loss: 0.5218 - val_accuracy: 0.7830\n",
      "Epoch 304/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4044 - accuracy: 0.8131 - val_loss: 0.5457 - val_accuracy: 0.7547\n",
      "Epoch 305/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4170 - accuracy: 0.7944 - val_loss: 0.5633 - val_accuracy: 0.7358\n",
      "Epoch 306/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4384 - accuracy: 0.7897 - val_loss: 0.5439 - val_accuracy: 0.7642\n",
      "Epoch 307/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4104 - accuracy: 0.7850 - val_loss: 0.5114 - val_accuracy: 0.7830\n",
      "Epoch 308/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.3915 - accuracy: 0.8084 - val_loss: 0.5226 - val_accuracy: 0.7830\n",
      "Epoch 309/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4258 - accuracy: 0.7897 - val_loss: 0.5192 - val_accuracy: 0.7925\n",
      "Epoch 310/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4268 - accuracy: 0.7897 - val_loss: 0.5147 - val_accuracy: 0.8019\n",
      "Epoch 311/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4389 - accuracy: 0.7710 - val_loss: 0.5110 - val_accuracy: 0.7925\n",
      "Epoch 312/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.3963 - accuracy: 0.8131 - val_loss: 0.5425 - val_accuracy: 0.7453\n",
      "Epoch 313/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4166 - accuracy: 0.8084 - val_loss: 0.5406 - val_accuracy: 0.7642\n",
      "Epoch 314/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.3917 - accuracy: 0.8084 - val_loss: 0.5196 - val_accuracy: 0.7925\n",
      "Epoch 315/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4039 - accuracy: 0.8037 - val_loss: 0.5108 - val_accuracy: 0.7830\n",
      "Epoch 316/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.3984 - accuracy: 0.7991 - val_loss: 0.6465 - val_accuracy: 0.6792\n",
      "Epoch 317/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4195 - accuracy: 0.8037 - val_loss: 0.5504 - val_accuracy: 0.7642\n",
      "Epoch 318/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4410 - accuracy: 0.7804 - val_loss: 0.5188 - val_accuracy: 0.7925\n",
      "Epoch 319/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4031 - accuracy: 0.8271 - val_loss: 0.5974 - val_accuracy: 0.7170\n",
      "Epoch 320/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.3739 - accuracy: 0.8131 - val_loss: 0.5920 - val_accuracy: 0.7264\n",
      "Epoch 321/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4411 - accuracy: 0.7804 - val_loss: 1.0874 - val_accuracy: 0.5660\n",
      "Epoch 322/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4936 - accuracy: 0.7617 - val_loss: 0.5398 - val_accuracy: 0.7642\n",
      "Epoch 323/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4471 - accuracy: 0.7757 - val_loss: 0.5946 - val_accuracy: 0.7170\n",
      "Epoch 324/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4219 - accuracy: 0.7991 - val_loss: 0.5191 - val_accuracy: 0.7736\n",
      "Epoch 325/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4192 - accuracy: 0.8084 - val_loss: 0.7442 - val_accuracy: 0.6415\n",
      "Epoch 326/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4548 - accuracy: 0.7804 - val_loss: 0.5113 - val_accuracy: 0.7830\n",
      "Epoch 327/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4316 - accuracy: 0.7850 - val_loss: 0.5597 - val_accuracy: 0.7358\n",
      "Epoch 328/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4315 - accuracy: 0.8037 - val_loss: 0.5212 - val_accuracy: 0.7830\n",
      "Epoch 329/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.3960 - accuracy: 0.8271 - val_loss: 0.5259 - val_accuracy: 0.7736\n",
      "Epoch 330/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4092 - accuracy: 0.8224 - val_loss: 0.5154 - val_accuracy: 0.7830\n",
      "Epoch 331/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4519 - accuracy: 0.7897 - val_loss: 0.5124 - val_accuracy: 0.7830\n",
      "Epoch 332/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.5862 - accuracy: 0.7570 - val_loss: 0.8672 - val_accuracy: 0.5849\n",
      "Epoch 333/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4174 - accuracy: 0.8224 - val_loss: 0.5240 - val_accuracy: 0.7642\n",
      "Epoch 334/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4122 - accuracy: 0.8131 - val_loss: 0.5144 - val_accuracy: 0.7830\n",
      "Epoch 335/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4299 - accuracy: 0.8178 - val_loss: 0.6092 - val_accuracy: 0.6981\n",
      "Epoch 336/360\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.4070 - accuracy: 0.7991 - val_loss: 0.5613 - val_accuracy: 0.7358\n",
      "Epoch 337/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4291 - accuracy: 0.7944 - val_loss: 0.5246 - val_accuracy: 0.7736\n",
      "Epoch 338/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.5460 - accuracy: 0.7570 - val_loss: 0.5798 - val_accuracy: 0.7358\n",
      "Epoch 339/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4001 - accuracy: 0.8037 - val_loss: 0.5203 - val_accuracy: 0.7830\n",
      "Epoch 340/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4254 - accuracy: 0.8131 - val_loss: 0.5175 - val_accuracy: 0.8019\n",
      "Epoch 341/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4047 - accuracy: 0.8271 - val_loss: 0.5217 - val_accuracy: 0.7736\n",
      "Epoch 342/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4451 - accuracy: 0.7710 - val_loss: 0.5247 - val_accuracy: 0.7736\n",
      "Epoch 343/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4513 - accuracy: 0.7664 - val_loss: 0.7910 - val_accuracy: 0.6038\n",
      "Epoch 344/360\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 0s 6ms/step - loss: 0.3990 - accuracy: 0.8037 - val_loss: 0.5148 - val_accuracy: 0.7925\n",
      "Epoch 345/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4459 - accuracy: 0.8037 - val_loss: 0.7169 - val_accuracy: 0.6604\n",
      "Epoch 346/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4111 - accuracy: 0.7710 - val_loss: 0.6050 - val_accuracy: 0.7075\n",
      "Epoch 347/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4273 - accuracy: 0.8037 - val_loss: 0.6077 - val_accuracy: 0.7264\n",
      "Epoch 348/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4385 - accuracy: 0.8037 - val_loss: 0.5948 - val_accuracy: 0.7170\n",
      "Epoch 349/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4337 - accuracy: 0.7757 - val_loss: 0.5289 - val_accuracy: 0.7642\n",
      "Epoch 350/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4224 - accuracy: 0.8037 - val_loss: 0.5111 - val_accuracy: 0.8019\n",
      "Epoch 351/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4159 - accuracy: 0.7897 - val_loss: 0.5201 - val_accuracy: 0.7736\n",
      "Epoch 352/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.3947 - accuracy: 0.7944 - val_loss: 0.5097 - val_accuracy: 0.7925\n",
      "Epoch 353/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.3921 - accuracy: 0.8131 - val_loss: 0.5948 - val_accuracy: 0.7170\n",
      "Epoch 354/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4300 - accuracy: 0.8131 - val_loss: 0.5325 - val_accuracy: 0.7642\n",
      "Epoch 355/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4040 - accuracy: 0.8037 - val_loss: 0.5545 - val_accuracy: 0.7453\n",
      "Epoch 356/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4175 - accuracy: 0.8131 - val_loss: 0.5193 - val_accuracy: 0.7830\n",
      "Epoch 357/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4271 - accuracy: 0.7897 - val_loss: 0.5606 - val_accuracy: 0.7264\n",
      "Epoch 358/360\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4594 - accuracy: 0.7710 - val_loss: 0.5388 - val_accuracy: 0.7547\n",
      "Epoch 359/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4424 - accuracy: 0.7944 - val_loss: 0.5117 - val_accuracy: 0.7925\n",
      "Epoch 360/360\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4185 - accuracy: 0.7897 - val_loss: 0.5247 - val_accuracy: 0.7547\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "classifier = Sequential()\n",
    "classifier.add(Dense(units = 10, activation = \"relu\", kernel_initializer = \"he_uniform\"))\n",
    "classifier.add(Dense(units = 10, activation = \"relu\", kernel_initializer = \"he_uniform\"))\n",
    "classifier.add(Dense(units = 1, activation = \"sigmoid\", kernel_initializer = \"glorot_uniform\"))\n",
    "classifier.compile(optimizer = \"adam\", loss = \"binary_crossentropy\", metrics = [\"accuracy\"])\n",
    "model = classifier.fit(x_train, y_train, batch_size = 10, epochs = 360, validation_split = 0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "acfef0e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = classifier.predict(x_test)\n",
    "y_pred = y_pred > 0.7\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8ec24765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of ANNH model: 85.0 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Accuracy score of ANNH model:\", accuracy_score(y_test, y_pred) * 100,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "99cd1ff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[31  2]\n",
      " [10 37]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29bba331",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
